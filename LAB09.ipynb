{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba07a9fc",
   "metadata": {},
   "source": [
    "Universidad del valle de Guatemala  \n",
    "Dpto. Ciencias de la computacion  \n",
    "Inteligencia Artificial  \n",
    "Alberto Suriano  \n",
    "\n",
    "Laboratorio 8\n",
    "Andres Quinto - 18288  \n",
    "Marlon Hernández - 15177  \n",
    "\n",
    "[Repositorio_aqui](https://github.com/AndresQuinto5/IA_LAB9.git)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa347f46",
   "metadata": {},
   "source": [
    "### Task 1 - Teoria\n",
    "\n",
    "1. Diga cual es la diferencia entre **Modelos de Markov y Hidden Markov Models**  \n",
    "\n",
    "    Un **Modelo de Markov** es un tipo de proceso estocástico que se utiliza para modelar la evolución temporal de un sistema que puede estar en uno de varios estados. En un **modelo de Markov**, el estado del sistema es visible directamente para el observador, y las probabilidades de transición entre estados son los únicos parámetros. La característica principal de un modelo de Markov es la **propiedad de Markov**, que establece que la probabilidad de que el sistema pase a un estado futuro solo depende del estado actual del sistema, no de su historia pasada.\n",
    "\n",
    "    Por otro lado, un **Modelo Oculto de Markov (HMM)** es una extensión de los modelos de Markov donde el estado del sistema **no es directamente visible** para el observador. En lugar de eso, el observador ve variables de salida que son influenciadas por el estado del sistema. En otras palabras, en un **HMM**, se asume que hay un proceso estocástico subyacente que no se puede observar (de ahí el término “oculto”), y solo se pueden observar ciertas variables que dependen del estado de este proceso oculto.\n",
    "\n",
    "    [What Is the Difference Between Markov Chains and Hidden Markov Models?](https://www.baeldung.com/cs/markov-chains-vs-hidden-markov-models)  \n",
    "    \n",
    "    [Modelo oculto de Márkov](https://www.wikiwand.com/es/Modelo_oculto_de_M%C3%A1rkov#google_vignette)\n",
    "\n",
    "2. Investigue qué son los factorial HMM (Hidden Markov Models)  \n",
    "\n",
    "    Los **Modelos Ocultos de Markov Factoriales (Factorial Hidden Markov Models, FHMMs)** son una extensión de los **Modelos Ocultos de Markov (HMMs)** en los que los estados ocultos se factorizan en varias cadenas de Markov independientes. En un **FHMM**, las emisiones (observaciones) son determinadas por la combinación de estos estados ocultos.\n",
    "\n",
    "    En un HMM, la información sobre el pasado se transmite a través de una única variable discreta: el estado oculto. Sin embargo, en un FHMM, cada parámetro de preferencia puede seguir un proceso de Markov distinto. Las probabilidades de transición son variables en el tiempo a nivel individual, afectadas por covariables de un término de retroalimentación de la decisión de compra anterior del consumidor, específico para cada proceso de Markov.\n",
    "\n",
    "    Los FHMMs son útiles para modelar procesos a lo largo del genoma y para modelar cambios temporales en modelos de elección, entre otras aplicaciones.\n",
    "\n",
    "    [Factorial Hidden Markov Models](https://link.springer.com/article/10.1023/A:1007425814087)  \n",
    "    [A Factorial Hidden Markov Model for the Analysis of Temporal Change in Choice Models | Customer Needs and Solutions - Springer](https://link.springer.com/article/10.1007/s40547-018-0088-0)  \n",
    "    [FactorialHMM: fast and exact inference in factorial hidden Markov models](https://academic.oup.com/bioinformatics/article/35/12/2162/5184283)  \n",
    "\n",
    "3. Especifique en sus propias palabras el algoritmo Forward Backward para HMM  \n",
    "\n",
    "    El algoritmo **Forward-Backward** es un método de inferencia para los Modelos Ocultos de Markov (HMMs). Este algoritmo calcula las marginales posteriores de todas las variables de estado ocultas dada una secuencia de observaciones. Se basa en la programación dinámica y tiene una complejidad lineal en la longitud de la secuencia.\n",
    "\n",
    "    **El algoritmo Forward-Backward consta de tres pasos principales:**\n",
    "\n",
    "    1. *Cálculo de las probabilidades hacia adelante (Forward probabilities):* Estas probabilidades proporcionan, para todos los estados ocultos, la probabilidad de terminar en un estado particular dado las primeras observaciones en la secuencia.  \n",
    "\n",
    "    2. *Cálculo de las probabilidades hacia atrás (Backward probabilities):* Estas probabilidades proporcionan la probabilidad de observar las observaciones restantes dado cualquier punto de partida.\n",
    "\n",
    "    3. *Cálculo de los valores suavizados (Smoothing):* Estos dos conjuntos de distribuciones de probabilidad se combinan para obtener la distribución sobre los estados en cualquier punto específico en el tiempo dado toda la secuencia de observación.\n",
    "\n",
    "    El algoritmo **Forward-Backward** puede usarse para encontrar el estado más probable para cualquier punto en el tiempo, pero no puede usarse para encontrar la secuencia de estados más probable.\n",
    "\n",
    "    [HMMs y el algoritmo Forward-Backward - Instituto de Tecnología de Massachusetts](https://people.csail.mit.edu/rameshvs/content/hmms.pdf)  \n",
    "    [Algoritmo Forward-Backward](https://en.wikipedia.org/wiki/Forward%E2%80%93backward_algorithm)  \n",
    "\n",
    "4. En el algoritmo de Forward Backward, por qué es necesario el paso de Backward (puede escribir ejemplos o casos para responder esta pregunta)  \n",
    "\n",
    "    El paso de **Backward** en el algoritmo **Forward-Backward** es esencial para calcular la probabilidad de las observaciones futuras dada la posición actual en la secuencia. Esto es crucial para calcular la distribución de probabilidad de los estados ocultos en cada punto de tiempo, dado todo el conjunto de observaciones.\n",
    "\n",
    "    Para entender mejor, consideremos un ejemplo simple de un HMM que modela el clima (soleado, lluvioso) basado en la elección de ropa (camiseta, suéter) de una persona. Supongamos que tenemos una secuencia de elecciones de ropa para una semana y queremos inferir el clima en cada día.\n",
    "\n",
    "    1. Paso **Forward**: Comenzamos desde el primer día y usamos las probabilidades de transición y emisión para calcular la probabilidad de que el clima sea soleado o lluvioso dado que la persona lleva una camiseta o un suéter. Continuamos este proceso para cada día sucesivo.\n",
    "\n",
    "    2. Paso **Backward**: Ahora, comenzamos desde el último día y calculamos la probabilidad de ver las elecciones de ropa para los días restantes dado que el clima es soleado o lluvioso. Este paso nos da una “vista hacia atrás” de la secuencia.\n",
    "\n",
    "    3. **Suavizado**: Finalmente, combinamos las probabilidades forward y backward para obtener la distribución de probabilidad de los estados ocultos en cada punto de tiempo, dado todo el conjunto de observaciones.\n",
    "    \n",
    "    Sin el paso de **Backward**, solo tendríamos una “vista hacia adelante” de la secuencia y no podríamos calcular correctamente las distribuciones de probabilidad de los estados ocultos. Por lo tanto, el paso de **Backward** es esencial para el algoritmo **Forward-Backward**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LAB08",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
